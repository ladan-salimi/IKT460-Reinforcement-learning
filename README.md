# Reinforcement-learning
This project explores the application of reinforcement learning in the 20 Questions game as a structured environment for evaluating dialogue systems and knowledge acquisition. The study initially implements the Reinforce algorithm for question-driven word guessing and extends the approach by integrating Proximal Policy Optimization (PPO) to compare their effectiveness. We also introduce a novel approach, proposed for the first time in this study. It involves training an RL agent to ask questions in a constant, human-interpretable format (e.g., "Does it have feathers?"). Unlike traditional methods that rely on entropy-based heuristics or random selection, this approach constrains the question space to a fixed template, improving consistency and interpretability. The agent learns to refine its questioning strategy using PPO-driven reinforcement learning, selecting the most informative constant-form questions at each step. Experimental results show that our RL-based approach outperforms an entropy-based heuristic system and achieves competitive performance in a noise-free environment.
