{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae2c5c2-5f49-4dfd-b444-1b3d8f204f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-02 16:41:44.692913: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740933704.712960 1146544 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740933704.718836 1146544 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-02 16:41:44.740508: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f1ce593-420d-4ad8-9e37-11291d70a243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Keywords: {'country': ['afghanistan', 'albania', 'algeria', 'andorra', 'angola', 'antigua and barbuda', 'argentina', 'armenia', 'australia', 'austria', 'azerbaijan', 'bahrain', 'bangladesh', 'barbados', 'belarus', 'belgium', 'belize', 'benin', 'bhutan', 'bolivia', 'bosnia and herzegovina', 'botswana', 'brazil', 'brunei', 'bulgaria', 'burkina faso', 'burundi', 'cambodia', 'cameroon', 'canada', 'cape verde', 'central african republic', 'chad', 'chile', 'china', 'colombia', 'comoros', 'congo', 'costa rica', 'croatia', 'cuba', 'cyprus', 'czech republic', 'democratic republic of the congo', 'denmark', 'djibouti', 'dominica', 'dominican republic', 'ecuador', 'egypt', 'el salvador', 'england', 'equatorial guinea', 'eritrea', 'estonia', 'ethiopia', 'federated states of micronesia', 'finland', 'france', 'gabon', 'gambia', 'georgia', 'germany', 'ghana', 'greece', 'grenada', 'guatemala', 'guinea', 'guinea bissau', 'guyana', 'haiti', 'honduras', 'hungary', 'iceland', 'india', 'indonesia', 'iran', 'iraq', 'ireland', 'israel', 'italy', 'jamaica', 'japan', 'jordan', 'kazakhstan', 'kenya', 'kiribati', 'kosovo', 'kuwait', 'kyrgyzstan', 'laos', 'latvia', 'lebanon', 'lesotho', 'liberia', 'libya', 'liechtenstein', 'lithuania', 'luxembourg', 'madagascar', 'malawi', 'malaysia', 'maldives', 'mali', 'malta', 'marshall islands', 'mauritania', 'mauritius', 'mexico', 'moldova', 'monaco', 'mongolia', 'montenegro', 'morocco', 'mozambique', 'myanmar', 'namibia', 'nauru', 'nepal', 'netherlands', 'new zealand', 'nicaragua', 'niger', 'nigeria', 'north korea', 'norway', 'oman', 'pakistan', 'palau', 'palestine', 'panama', 'papua new guinea', 'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'qatar', 'romania', 'russia', 'rwanda', 'saint kitts and nevis', 'saint lucia', 'saint vincent and the grenadines', 'samoa', 'san marino', 'sao tome and principe', 'saudi arabia', 'senegal', 'serbia', 'seychelles', 'sierra leone', 'singapore', 'slovakia', 'slovenia', 'solomon islands', 'somalia', 'south africa', 'south korea', 'spain', 'sudan', 'suriname', 'swaziland', 'sweden', 'switzerland', 'syria', 'taiwan', 'tajikistan', 'tanzania', 'thailand', 'togo', 'tonga', 'trinidad and tobago', 'tunisia', 'turkey', 'turkmenistan', 'tuvalu', 'uganda', 'ukraine', 'united arab emirates', 'united kingdom', 'united states of america', 'uruguay', 'uzbekistan', 'vanuatu', 'venezuela', 'vietnam', 'yemen', 'zambia', 'zimbabwe'], 'city': ['amsterdam netherlands', 'anaheim california', 'austin texas', 'auckland new zealand', 'asheville north carolina', 'ashgabat turkmenistan', 'athens greece', 'athens georgia', 'atlanta georgia', 'antwerp belgium', 'adelaide australia', 'astana kazakhstan', 'asuncion paraguay', 'algiers algeria', 'acapulco mexico', 'ankara turkey', 'baghdad iraq', 'bangkok thailand', 'beijing china', 'berlin germany', 'boston massachusetts', 'buenos aires argentina', 'bursa turkey', 'bucharest romania', 'baltimore maryland', 'beirut lebanon', 'belfast northern ireland', 'bratislava slovakia', 'belgrade serbia', 'budapest hungary', 'baku azerbaijan', 'bordeaux france', 'busan south korea', 'brussels belgium', 'bangalore india', 'calgary canada', 'chicago illinois', 'copenhagen denmark', 'columbus ohio', 'cologne germany', 'cairo egypt', 'cape town south africa', 'caracas venezuela', 'cleveland ohio', 'cork ireland', 'christchurch new zealand', 'casablanca morocco', 'chengdu china', 'cannes france', 'canberra australia', 'dallas texas', 'dubai united arab emirates', 'dhaka bangladesh', 'dakar senegal', 'delhi india', 'durban south africa', 'dublin ireland', 'dalian china', 'doha qatar', 'denver colorado', 'dusseldorf germany', 'davao city philippines', 'darwin australia', 'dunfermline scotland', 'daegu south korea', 'damascus syria', 'dar es salaam tanzania', 'edinburgh scotland', 'edmonton canada', 'essen germany', 'evora portugal', 'ensenada mexico', 'el paso texas', 'enugu nigeria', 'enschede netherlands', 'eureka california', 'erie pennsylvania', 'eilat israel', 'essentuki russia', 'esbjerg denmark', 'fez morocco', 'florence italy', 'frankfurt germany', 'fort worth texas', 'fukuoka japan', 'faisalabad pakistan', 'fujairah united arab emirates', 'funafuti tuvalu', 'florianopolis brazil', 'flinders australia', 'faro portugal', 'fujairah united arab emirates', 'fort mcmurray canada', 'fortaleza brazil', 'friesland netherlands', 'funchal portugal', 'fuzhou china', 'fresno california', 'fermoy ireland', 'fukushima japan', 'glasgow scotland', 'guangzhou china', 'gdansk poland', 'guatemala city guatemala', 'guwahati india', 'gyeongju south korea', 'genoa italy', 'grahamstown south africa', 'guadalajara mexico', 'geneva switzerland', 'graz austria', 'gwangju south korea', 'houston texas', 'hamburg germany', 'hanoi vietnam', 'helsinki finland', 'ho chi minh city vietnam', 'haifa israel', 'havana cuba', 'hong kong china', 'hobart australia', 'hangzhou china', 'hilo hawaii', 'hermosillo mexico', 'honolulu hawaii', 'helsingborg sweden', 'hiroshima japan', 'harare zimbabwe', 'istanbul turkey', 'indianapolis indiana', 'ibadan nigeria', 'istanbul turkey', 'indore india', 'izmir turkey', 'isafahan iran', 'incheon south korea', 'innsbruck austria', 'islamabad pakistan', 'ingolstadt germany', 'irvine california', 'irkutsk russia', 'jakarta indonesia', 'jerusalem israel', 'jacksonville florida', 'johannesburg south africa', 'jabalpur india', 'jinan china', 'jeddah saudi arabia', 'jalapa guatemala', 'jackson mississippi', 'juarez mexico', 'jabalpur india', 'jining china', 'kampala uganda', 'kathmandu nepal', 'kaunas lithuania', 'kuala lumpur malaysia', 'kyoto japan', 'kagoshima japan', 'karachi pakistan', 'kiev ukraine', 'kingston jamaica', 'kolkata india', 'kunming china', 'kabul afghanistan', 'kyiv ukraine', 'kawasaki japan', 'london england', 'la paz bolivia', 'los angeles california', 'lima peru', 'lyon france', 'lisbon portugal', 'luanda angola', 'liverpool england', 'lagos nigeria', 'leeds england', 'ljubljana slovenia', 'lyon france', 'lima peru', 'lviv ukraine', 'leipzig germany', 'lusaka zambia', 'lausanne switzerland', 'madrid spain', 'manchester england', 'mexico city mexico', 'manila philippines', 'montreal canada', 'milan italy', 'moscow russia', 'madrid spain', 'mumbai india', 'managua nicaragua', 'melbourne australia', 'marrakech morocco', 'miami florida', 'minneapolis minnesota', 'mecca saudi arabia', 'melbourne australia', 'makati philippines', 'monterrey mexico', 'nagoya japan', 'new york city', 'nanjing china', 'new delhi india', 'nantes france', 'noida india', 'newcastle upon tyne england', 'nice france', 'nurumberg germany', 'new orleans louisiana', 'nairobi kenya', 'naples italy', 'noosa australia', 'osaka japan', 'oklahoma city oklahoma', 'oslo norway', 'oxford england', 'ottawa canada', 'orsay france', 'odessa ukraine', 'oranjestad aruba', 'orlando florida', 'ostrava czech republic', 'oaxaca mexico', 'otago new zealand', 'ouagadougou burkina faso', 'odense denmark', 'oulu finland', 'paris france', 'prague czech republic', 'porto portugal', 'philadelphia pennsylvania', 'pyeongyang north korea', 'perth australia', 'plovdiv bulgaria', 'pattaya thailand', 'portland oregon', 'phoenix arizona', 'porto alegre brazil', 'peshawar pakistan', 'panama city panama', 'rome italy', 'rio de janeiro brazil', 'riyadh saudi arabia', 'reykjavik iceland', 'rotterdam netherlands', 'ras al khaimah united arab emirates', 'raleigh north carolina', 'riga latvia', 'rochester new york', 'recife brazil', 'san francisco california', 'sydney australia', 'singapore', 'seoul south korea', 'stockholm sweden', 'santiago chile', 'san diego california', 'shanghai china', 'sao paulo brazil', 'stuttgart germany', 'sevilla spain', 'saskatoon canada', 'san salvador el salvador', 'sofia bulgaria', 'seattle washington', 'tokyo japan', 'torino italy', 'tunis tunisia', 'tashkent uzbekistan', 'toronto canada', 'tirana albania', 'tijuana mexico', 'turin italy', 'tokyo japan', 'thessaloniki greece', 'taegu south korea', 'taksim turkey', 'taipei taiwan', 'tripoli libya', 'tokyo japan', 'ulaanbaatar mongolia', 'ubud indonesia', 'uppsala sweden', 'urumqi china', 'vaduz liechtenstein', 'vancouver canada', 'valencia spain', 'vigo spain', 'valparaiso chile', 'vladivostok russia', 'vienna austria', 'vilnius lithuania', 'villarreal spain', 'washington dc', 'westminster england', 'wilmington delaware', 'wroclaw poland', 'warsaw poland', 'wellington new zealand', 'winnipeg manitoba', 'warsaw poland', 'wuhan china', 'yokohama japan', 'york england', 'yaounde cameroon', 'yuma arizona', 'ypres belgium', 'yakutsk russia', 'yerevan armenia', 'yanbu saudi arabia', 'yogyakarta indonesia', 'yekaterinburg russia', 'zacatecas mexico', 'zunyi china', 'zincantan mexico', 'zagreb croatia', 'zeeland netherlands', 'zhongshan china', 'zanzibar tanzania', 'zurich switzerland', 'zaragoza spain'], 'landmark': ['denali', 'mount saint lias', 'mount whitney', 'mount rainier', 'iztaccihuatl', 'grand teton', 'gannett peak', 'mount adams', 'mount saint helens', 'mount shasta', 'mount saint helens', 'pikes peak', 'aconcagua', 'fitz roy', 'cotopaxi', 'chimborazo', 'mont blanc', 'zugspitze', 'mount elbrus', 'mount etna', 'everest', 'k2', 'lhotse', 'makalu', 'cho oyu', 'manaslu', 'annapurna', 'dhaulagiri', 'nanga parbat', 'kangchenjunga', 'mount fuji', 'kilimanjaro', 'meru', 'aoraki', 'haleakala', 'puncak jaya', 'sumantri', 'amazon', 'colorado river', 'dnieper', 'ganges', 'illinois river', 'mississippi river', 'nile', 'rhine', 'yangtze river', 'yellow river', 'zambezi river', 'yenisei river']}\n"
     ]
    }
   ],
   "source": [
    "# Load JSON file\n",
    "with open(\"keywords.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert JSON list into a dictionary\n",
    "keywords = {entry[\"category\"]: [item[\"keyword\"] for item in entry[\"words\"]] for entry in data}\n",
    "\n",
    "# Print to verify structure\n",
    "print(\"Processed Keywords:\", keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86b90f2-cc5d-42dc-aa03-ea8403e4e857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: city (Secret Word: glasgow scotland)\n"
     ]
    }
   ],
   "source": [
    "# Load JSON data\n",
    "with open(\"keywords.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert JSON to a structured dictionary\n",
    "keywords = {}\n",
    "for entry in data:\n",
    "    category = entry[\"category\"]\n",
    "    words = [item[\"keyword\"] for item in entry[\"words\"]]\n",
    "    keywords[category] = words\n",
    "\n",
    "# Select a random category\n",
    "category = random.choice(list(keywords.keys()))\n",
    "\n",
    "# Select a secret word from that category\n",
    "secret_word = random.choice(keywords[category])\n",
    "\n",
    "print(f\"Category: {category} (Secret Word: {secret_word})\")\n",
    "\n",
    "# Initialize game state\n",
    "state = f\"You are playing 20 Questions. Think of a {category}.\"\n",
    "asked_questions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c9733cc-6297-431f-9886-8046069e2465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ladans/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "class T5QuestionGenerator:\n",
    "    def __init__(self, model_name=\"t5-small\"):\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    def generate_question(self, category, keywords):\n",
    "        \"\"\"Generates a question using T5-small based on category and keywords.\"\"\"\n",
    "        truncated_keywords = \", \".join(keywords[:5])  # Limit to 5 keywords for efficiency\n",
    "        input_text = f\"Generate a question about {category}: {truncated_keywords}\"\n",
    "\n",
    "        inputs = self.tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=50)\n",
    "\n",
    "        # Generate question\n",
    "        outputs = self.model.generate(inputs[\"input_ids\"], max_new_tokens=20, num_return_sequences=1, do_sample=True, temperature=0.7)\n",
    "\n",
    "        question = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "733a37bf-95fc-41bb-9941-5eb034dfd1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "class TwentyQuestionsEnv(gym.Env):\n",
    "    def __init__(self, keywords):\n",
    "        super(TwentyQuestionsEnv, self).__init__()\n",
    "\n",
    "        # Initialize T5 question generator\n",
    "        self.qg = T5QuestionGenerator()\n",
    "        self.keywords = keywords\n",
    "\n",
    "        # Select a random category and word\n",
    "        self.category = random.choice(list(self.keywords.keys()))\n",
    "        self.secret_word = random.choice(self.keywords[self.category])\n",
    "\n",
    "        # Define action & observation space\n",
    "        self.action_space = spaces.Discrete(20)  # Max 20 questions\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(20,), dtype=np.float32)\n",
    "\n",
    "        # Initialize game state\n",
    "        self.asked_questions = []\n",
    "        self.done = False\n",
    "        self.steps = 0\n",
    "        self.max_steps = 20\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Agent asks a question and receives a response\"\"\"\n",
    "        if self.done:\n",
    "            return np.array(self._get_state()), 0, True, {}\n",
    "\n",
    "        # Generate a question using T5-small\n",
    "        question = self.qg.generate_question(self.category, self.keywords[self.category])\n",
    "\n",
    "        # Simulate the answer\n",
    "        answer = self._simulate_answer(question)\n",
    "\n",
    "        # Calculate reward\n",
    "        reward = self._calculate_reward(question, answer)\n",
    "\n",
    "        # Track asked questions\n",
    "        self.asked_questions.append((question, answer))\n",
    "\n",
    "        # Check termination condition\n",
    "        self.steps += 1\n",
    "        if self.steps >= self.max_steps or answer == \"Yes, correct!\":\n",
    "            self.done = True\n",
    "\n",
    "        return np.array(self._get_state()), reward, self.done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Resets the environment for a new game\"\"\"\n",
    "        self.category = random.choice(list(self.keywords.keys()))\n",
    "        self.secret_word = random.choice(self.keywords[self.category])\n",
    "        self.asked_questions = []\n",
    "        self.done = False\n",
    "        self.steps = 0\n",
    "        return np.array(self._get_state())\n",
    "\n",
    "    def _get_state(self):\n",
    "        \"\"\"Returns the current game state\"\"\"\n",
    "        return [len(self.asked_questions)]  # Simplified representation\n",
    "\n",
    "    def _simulate_answer(self, question):\n",
    "        \"\"\"Simulates Yes/No/Maybe answers\"\"\"\n",
    "        if any(keyword in question.lower() for keyword in self.keywords[self.category]):\n",
    "            return random.choices([\"Yes\", \"Maybe\"], weights=[0.8, 0.2], k=1)[0]\n",
    "        return random.choices([\"No\", \"Maybe\"], weights=[0.7, 0.3], k=1)[0]\n",
    "\n",
    "    def _calculate_reward(self, question, answer):\n",
    "        \"\"\"Rewards/Penalizes the agent based on question quality\"\"\"\n",
    "        if answer == \"Yes\":\n",
    "            return 1  # Good question\n",
    "        elif answer == \"Maybe\":\n",
    "            return -0.5  # Weak question\n",
    "        elif answer == \"No\":\n",
    "            return -2  # Bad question\n",
    "        return -1  # Default penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28101eeb-2ca8-412d-821e-a73bea2588ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class PPOAgent:\n",
    "    def __init__(self, state_size, action_size, lr=0.001):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.lr = lr\n",
    "\n",
    "        # Create models\n",
    "        self.policy_model = self._build_policy_model()\n",
    "        self.value_model = self._build_value_model()\n",
    "\n",
    "        # 🔹 Ensure models are built before use\n",
    "        self.policy_model.build((None, self.state_size))\n",
    "        self.value_model.build((None, self.state_size))\n",
    "\n",
    "        # Optimizers\n",
    "        self.policy_optimizer = tf.keras.optimizers.Adam(learning_rate=self.lr)\n",
    "        self.value_optimizer = tf.keras.optimizers.Adam(learning_rate=self.lr)\n",
    "\n",
    "    def _build_policy_model(self):\n",
    "        \"\"\"Defines the policy network (actor).\"\"\"\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='relu', input_shape=(self.state_size,)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(self.action_size, activation='softmax')\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "    def _build_value_model(self):\n",
    "        \"\"\"Defines the value network (critic).\"\"\"\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='relu', input_shape=(self.state_size,)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='linear')\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "    def get_action(self, state):\n",
    "        \"\"\"Selects an action (question)\"\"\"\n",
    "        state = np.array([state], dtype=np.float32)  # 🔹 Ensure correct shape\n",
    "        probs = self.policy_model.predict(state, verbose=0)[0]\n",
    "        return np.random.choice(self.action_size, p=probs)\n",
    "\n",
    "    def train(self, states, actions, rewards):\n",
    "        \"\"\"Trains PPO Agent\"\"\"\n",
    "        states = np.array(states, dtype=np.float32)\n",
    "        actions = np.array(actions, dtype=np.int32)\n",
    "        rewards = np.array(rewards, dtype=np.float32)\n",
    "\n",
    "        # Compute advantages\n",
    "        advantages = rewards - self.value_model.predict(states, verbose=0).flatten()\n",
    "\n",
    "        with tf.GradientTape() as policy_tape, tf.GradientTape() as value_tape:\n",
    "            probs = self.policy_model(states)\n",
    "            action_masks = tf.one_hot(actions, self.action_size)\n",
    "            selected_probs = tf.reduce_sum(probs * action_masks, axis=1)\n",
    "\n",
    "            # PPO Loss\n",
    "            loss = -tf.reduce_mean(tf.math.log(selected_probs + 1e-10) * advantages)\n",
    "\n",
    "            # Value Loss\n",
    "            value_preds = self.value_model(states)\n",
    "            value_loss = tf.reduce_mean(tf.square(rewards - value_preds))\n",
    "\n",
    "        policy_grads = policy_tape.gradient(loss, self.policy_model.trainable_variables)\n",
    "        value_grads = value_tape.gradient(value_loss, self.value_model.trainable_variables)\n",
    "\n",
    "        self.policy_optimizer.apply_gradients(zip(policy_grads, self.policy_model.trainable_variables))\n",
    "        self.value_optimizer.apply_gradients(zip(value_grads, self.value_model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8f312f9-51f5-431a-b1fb-10eab890d3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1740933728.644560 1146883 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "E0000 00:00:1740933728.655819 1146883 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2025-03-02 16:42:08.667477: W tensorflow/core/framework/op_kernel.cc:1841] OP_REQUIRES failed at xla_ops.cc:577 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2025-03-02 16:42:08.667516: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 1043, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipykernel_1146544/991478879.py\", line 12, in <module>\n\n  File \"/tmp/ipykernel_1146544/3126030660.py\", line 45, in get_action\n\n  File \"/home/ladans/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/ladans/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 562, in predict\n\n  File \"/home/ladans/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 259, in one_step_on_data_distributed\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_data_distributed_479]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m states, actions, rewards \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(env\u001b[38;5;241m.\u001b[39mmax_steps):\n\u001b[0;32m---> 12\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     15\u001b[0m     states\u001b[38;5;241m.\u001b[39mappend(state)\n",
      "Cell \u001b[0;32mIn[6], line 45\u001b[0m, in \u001b[0;36mPPOAgent.get_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Selects an action (question)\"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([state], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# 🔹 Ensure correct shape\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_size, p\u001b[38;5;241m=\u001b[39mprobs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 1043, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipykernel_1146544/991478879.py\", line 12, in <module>\n\n  File \"/tmp/ipykernel_1146544/3126030660.py\", line 45, in get_action\n\n  File \"/home/ladans/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/ladans/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 562, in predict\n\n  File \"/home/ladans/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 259, in one_step_on_data_distributed\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_data_distributed_479]"
     ]
    }
   ],
   "source": [
    "env = TwentyQuestionsEnv(keywords)\n",
    "agent = PPOAgent(state_size=1, action_size=20)\n",
    "\n",
    "#tf.keras.backend.clear_session()  # Clears the previous model state\n",
    "\n",
    "for episode in range(100):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    states, actions, rewards = [], [], []\n",
    "\n",
    "    for t in range(env.max_steps):\n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    agent.train(states, actions, rewards)\n",
    "    print(f\"Episode {episode+1}: Total Reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ecff8-8f1c-459f-9209-bee6b1137951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
