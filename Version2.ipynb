{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87768bf5-9435-49e2-9888-fd110b5d2879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a version 2 using t2-small language model to generate the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329d8e6f-2558-4658-9523-e33c3cda5f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "#!pip install --upgrade typing_extensions torch\n",
    "#!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae2c5c2-5f49-4dfd-b444-1b3d8f204f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 07:14:15.813033: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-05 07:14:15.825727: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741158855.837642   91786 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741158855.841171   91786 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-05 07:14:15.855816: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94410257-5cec-4a01-a35e-a638f706af54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ladans/Reinforcement learning/GPT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f1ce593-420d-4ad8-9e37-11291d70a243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Keywords: {'country': ['afghanistan', 'albania', 'algeria', 'andorra', 'angola', 'antigua and barbuda', 'argentina', 'armenia', 'australia', 'austria', 'azerbaijan', 'bahrain', 'bangladesh', 'barbados', 'belarus', 'belgium', 'belize', 'benin', 'bhutan', 'bolivia', 'bosnia and herzegovina', 'botswana', 'brazil', 'brunei', 'bulgaria', 'burkina faso', 'burundi', 'cambodia', 'cameroon', 'canada', 'cape verde', 'central african republic', 'chad', 'chile', 'china', 'colombia', 'comoros', 'congo', 'costa rica', 'croatia', 'cuba', 'cyprus', 'czech republic', 'democratic republic of the congo', 'denmark', 'djibouti', 'dominica', 'dominican republic', 'ecuador', 'egypt', 'el salvador', 'england', 'equatorial guinea', 'eritrea', 'estonia', 'ethiopia', 'federated states of micronesia', 'finland', 'france', 'gabon', 'gambia', 'georgia', 'germany', 'ghana', 'greece', 'grenada', 'guatemala', 'guinea', 'guinea bissau', 'guyana', 'haiti', 'honduras', 'hungary', 'iceland', 'india', 'indonesia', 'iran', 'iraq', 'ireland', 'israel', 'italy', 'jamaica', 'japan', 'jordan', 'kazakhstan', 'kenya', 'kiribati', 'kosovo', 'kuwait', 'kyrgyzstan', 'laos', 'latvia', 'lebanon', 'lesotho', 'liberia', 'libya', 'liechtenstein', 'lithuania', 'luxembourg', 'madagascar', 'malawi', 'malaysia', 'maldives', 'mali', 'malta', 'marshall islands', 'mauritania', 'mauritius', 'mexico', 'moldova', 'monaco', 'mongolia', 'montenegro', 'morocco', 'mozambique', 'myanmar', 'namibia', 'nauru', 'nepal', 'netherlands', 'new zealand', 'nicaragua', 'niger', 'nigeria', 'north korea', 'norway', 'oman', 'pakistan', 'palau', 'palestine', 'panama', 'papua new guinea', 'paraguay', 'peru', 'philippines', 'poland', 'portugal', 'qatar', 'romania', 'russia', 'rwanda', 'saint kitts and nevis', 'saint lucia', 'saint vincent and the grenadines', 'samoa', 'san marino', 'sao tome and principe', 'saudi arabia', 'senegal', 'serbia', 'seychelles', 'sierra leone', 'singapore', 'slovakia', 'slovenia', 'solomon islands', 'somalia', 'south africa', 'south korea', 'spain', 'sudan', 'suriname', 'swaziland', 'sweden', 'switzerland', 'syria', 'taiwan', 'tajikistan', 'tanzania', 'thailand', 'togo', 'tonga', 'trinidad and tobago', 'tunisia', 'turkey', 'turkmenistan', 'tuvalu', 'uganda', 'ukraine', 'united arab emirates', 'united kingdom', 'united states of america', 'uruguay', 'uzbekistan', 'vanuatu', 'venezuela', 'vietnam', 'yemen', 'zambia', 'zimbabwe'], 'city': ['amsterdam netherlands', 'anaheim california', 'austin texas', 'auckland new zealand', 'asheville north carolina', 'ashgabat turkmenistan', 'athens greece', 'athens georgia', 'atlanta georgia', 'antwerp belgium', 'adelaide australia', 'astana kazakhstan', 'asuncion paraguay', 'algiers algeria', 'acapulco mexico', 'ankara turkey', 'baghdad iraq', 'bangkok thailand', 'beijing china', 'berlin germany', 'boston massachusetts', 'buenos aires argentina', 'bursa turkey', 'bucharest romania', 'baltimore maryland', 'beirut lebanon', 'belfast northern ireland', 'bratislava slovakia', 'belgrade serbia', 'budapest hungary', 'baku azerbaijan', 'bordeaux france', 'busan south korea', 'brussels belgium', 'bangalore india', 'calgary canada', 'chicago illinois', 'copenhagen denmark', 'columbus ohio', 'cologne germany', 'cairo egypt', 'cape town south africa', 'caracas venezuela', 'cleveland ohio', 'cork ireland', 'christchurch new zealand', 'casablanca morocco', 'chengdu china', 'cannes france', 'canberra australia', 'dallas texas', 'dubai united arab emirates', 'dhaka bangladesh', 'dakar senegal', 'delhi india', 'durban south africa', 'dublin ireland', 'dalian china', 'doha qatar', 'denver colorado', 'dusseldorf germany', 'davao city philippines', 'darwin australia', 'dunfermline scotland', 'daegu south korea', 'damascus syria', 'dar es salaam tanzania', 'edinburgh scotland', 'edmonton canada', 'essen germany', 'evora portugal', 'ensenada mexico', 'el paso texas', 'enugu nigeria', 'enschede netherlands', 'eureka california', 'erie pennsylvania', 'eilat israel', 'essentuki russia', 'esbjerg denmark', 'fez morocco', 'florence italy', 'frankfurt germany', 'fort worth texas', 'fukuoka japan', 'faisalabad pakistan', 'fujairah united arab emirates', 'funafuti tuvalu', 'florianopolis brazil', 'flinders australia', 'faro portugal', 'fujairah united arab emirates', 'fort mcmurray canada', 'fortaleza brazil', 'friesland netherlands', 'funchal portugal', 'fuzhou china', 'fresno california', 'fermoy ireland', 'fukushima japan', 'glasgow scotland', 'guangzhou china', 'gdansk poland', 'guatemala city guatemala', 'guwahati india', 'gyeongju south korea', 'genoa italy', 'grahamstown south africa', 'guadalajara mexico', 'geneva switzerland', 'graz austria', 'gwangju south korea', 'houston texas', 'hamburg germany', 'hanoi vietnam', 'helsinki finland', 'ho chi minh city vietnam', 'haifa israel', 'havana cuba', 'hong kong china', 'hobart australia', 'hangzhou china', 'hilo hawaii', 'hermosillo mexico', 'honolulu hawaii', 'helsingborg sweden', 'hiroshima japan', 'harare zimbabwe', 'istanbul turkey', 'indianapolis indiana', 'ibadan nigeria', 'istanbul turkey', 'indore india', 'izmir turkey', 'isafahan iran', 'incheon south korea', 'innsbruck austria', 'islamabad pakistan', 'ingolstadt germany', 'irvine california', 'irkutsk russia', 'jakarta indonesia', 'jerusalem israel', 'jacksonville florida', 'johannesburg south africa', 'jabalpur india', 'jinan china', 'jeddah saudi arabia', 'jalapa guatemala', 'jackson mississippi', 'juarez mexico', 'jabalpur india', 'jining china', 'kampala uganda', 'kathmandu nepal', 'kaunas lithuania', 'kuala lumpur malaysia', 'kyoto japan', 'kagoshima japan', 'karachi pakistan', 'kiev ukraine', 'kingston jamaica', 'kolkata india', 'kunming china', 'kabul afghanistan', 'kyiv ukraine', 'kawasaki japan', 'london england', 'la paz bolivia', 'los angeles california', 'lima peru', 'lyon france', 'lisbon portugal', 'luanda angola', 'liverpool england', 'lagos nigeria', 'leeds england', 'ljubljana slovenia', 'lyon france', 'lima peru', 'lviv ukraine', 'leipzig germany', 'lusaka zambia', 'lausanne switzerland', 'madrid spain', 'manchester england', 'mexico city mexico', 'manila philippines', 'montreal canada', 'milan italy', 'moscow russia', 'madrid spain', 'mumbai india', 'managua nicaragua', 'melbourne australia', 'marrakech morocco', 'miami florida', 'minneapolis minnesota', 'mecca saudi arabia', 'melbourne australia', 'makati philippines', 'monterrey mexico', 'nagoya japan', 'new york city', 'nanjing china', 'new delhi india', 'nantes france', 'noida india', 'newcastle upon tyne england', 'nice france', 'nurumberg germany', 'new orleans louisiana', 'nairobi kenya', 'naples italy', 'noosa australia', 'osaka japan', 'oklahoma city oklahoma', 'oslo norway', 'oxford england', 'ottawa canada', 'orsay france', 'odessa ukraine', 'oranjestad aruba', 'orlando florida', 'ostrava czech republic', 'oaxaca mexico', 'otago new zealand', 'ouagadougou burkina faso', 'odense denmark', 'oulu finland', 'paris france', 'prague czech republic', 'porto portugal', 'philadelphia pennsylvania', 'pyeongyang north korea', 'perth australia', 'plovdiv bulgaria', 'pattaya thailand', 'portland oregon', 'phoenix arizona', 'porto alegre brazil', 'peshawar pakistan', 'panama city panama', 'rome italy', 'rio de janeiro brazil', 'riyadh saudi arabia', 'reykjavik iceland', 'rotterdam netherlands', 'ras al khaimah united arab emirates', 'raleigh north carolina', 'riga latvia', 'rochester new york', 'recife brazil', 'san francisco california', 'sydney australia', 'singapore', 'seoul south korea', 'stockholm sweden', 'santiago chile', 'san diego california', 'shanghai china', 'sao paulo brazil', 'stuttgart germany', 'sevilla spain', 'saskatoon canada', 'san salvador el salvador', 'sofia bulgaria', 'seattle washington', 'tokyo japan', 'torino italy', 'tunis tunisia', 'tashkent uzbekistan', 'toronto canada', 'tirana albania', 'tijuana mexico', 'turin italy', 'tokyo japan', 'thessaloniki greece', 'taegu south korea', 'taksim turkey', 'taipei taiwan', 'tripoli libya', 'tokyo japan', 'ulaanbaatar mongolia', 'ubud indonesia', 'uppsala sweden', 'urumqi china', 'vaduz liechtenstein', 'vancouver canada', 'valencia spain', 'vigo spain', 'valparaiso chile', 'vladivostok russia', 'vienna austria', 'vilnius lithuania', 'villarreal spain', 'washington dc', 'westminster england', 'wilmington delaware', 'wroclaw poland', 'warsaw poland', 'wellington new zealand', 'winnipeg manitoba', 'warsaw poland', 'wuhan china', 'yokohama japan', 'york england', 'yaounde cameroon', 'yuma arizona', 'ypres belgium', 'yakutsk russia', 'yerevan armenia', 'yanbu saudi arabia', 'yogyakarta indonesia', 'yekaterinburg russia', 'zacatecas mexico', 'zunyi china', 'zincantan mexico', 'zagreb croatia', 'zeeland netherlands', 'zhongshan china', 'zanzibar tanzania', 'zurich switzerland', 'zaragoza spain'], 'landmark': ['denali', 'mount saint lias', 'mount whitney', 'mount rainier', 'iztaccihuatl', 'grand teton', 'gannett peak', 'mount adams', 'mount saint helens', 'mount shasta', 'mount saint helens', 'pikes peak', 'aconcagua', 'fitz roy', 'cotopaxi', 'chimborazo', 'mont blanc', 'zugspitze', 'mount elbrus', 'mount etna', 'everest', 'k2', 'lhotse', 'makalu', 'cho oyu', 'manaslu', 'annapurna', 'dhaulagiri', 'nanga parbat', 'kangchenjunga', 'mount fuji', 'kilimanjaro', 'meru', 'aoraki', 'haleakala', 'puncak jaya', 'sumantri', 'amazon', 'colorado river', 'dnieper', 'ganges', 'illinois river', 'mississippi river', 'nile', 'rhine', 'yangtze river', 'yellow river', 'zambezi river', 'yenisei river']}\n"
     ]
    }
   ],
   "source": [
    "# Load JSON file\n",
    "with open(\"keywords.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert JSON list into a dictionary\n",
    "keywords = {entry[\"category\"]: [item[\"keyword\"] for item in entry[\"words\"]] for entry in data}\n",
    "\n",
    "# Print to verify structure\n",
    "print(\"Processed Keywords:\", keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f86b90f2-cc5d-42dc-aa03-ea8403e4e857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: city (Secret Word: geneva switzerland)\n"
     ]
    }
   ],
   "source": [
    "# Load JSON data\n",
    "with open(\"keywords.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert JSON to a structured dictionary\n",
    "keywords = {}\n",
    "for entry in data:\n",
    "    category = entry[\"category\"]\n",
    "    words = [item[\"keyword\"] for item in entry[\"words\"]]\n",
    "    keywords[category] = words\n",
    "\n",
    "# Select a random category\n",
    "category = random.choice(list(keywords.keys()))\n",
    "\n",
    "# Select a secret word from that category\n",
    "secret_word = random.choice(keywords[category])\n",
    "\n",
    "print(f\"Category: {category} (Secret Word: {secret_word})\")\n",
    "\n",
    "# Initialize game state\n",
    "state = f\"You are playing 20 Questions. Think of a {category}.\"\n",
    "asked_questions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c9733cc-6297-431f-9886-8046069e2465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "class T5QuestionGenerator:\n",
    "    def __init__(self, model_name=\"t5-small\"):\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    def generate_question(self, category, keywords):\n",
    "        \"\"\"Generates a question using T5-small based on category and keywords.\"\"\"\n",
    "        truncated_keywords = \", \".join(keywords[:5])  # Limit to 5 keywords for efficiency\n",
    "        input_text = f\"Generate a question about {category}: {truncated_keywords}\"\n",
    "\n",
    "        inputs = self.tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=50)\n",
    "\n",
    "        # Generate question\n",
    "        outputs = self.model.generate(inputs[\"input_ids\"], max_new_tokens=20, num_return_sequences=1, do_sample=True, temperature=0.7)\n",
    "\n",
    "        question = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "733a37bf-95fc-41bb-9941-5eb034dfd1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "class TwentyQuestionsEnv(gym.Env):\n",
    "    def __init__(self, keywords):\n",
    "        super(TwentyQuestionsEnv, self).__init__()\n",
    "\n",
    "        # Initialize T5 question generator\n",
    "        self.qg = T5QuestionGenerator()\n",
    "        self.keywords = keywords\n",
    "\n",
    "        # Select a random category and word\n",
    "        self.category = random.choice(list(self.keywords.keys()))\n",
    "        self.secret_word = random.choice(self.keywords[self.category])\n",
    "\n",
    "        # Define action & observation space\n",
    "        self.action_space = spaces.Discrete(20)  # Max 20 questions\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(20,), dtype=np.float32)\n",
    "\n",
    "        # Initialize game state\n",
    "        self.asked_questions = []\n",
    "        self.done = False\n",
    "        self.steps = 0\n",
    "        self.max_steps = 20\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Agent asks a question and receives a response\"\"\"\n",
    "        if self.done:\n",
    "            return np.array(self._get_state()), 0, True, {}\n",
    "\n",
    "        # Generate a question using T5-small\n",
    "        question = self.qg.generate_question(self.category, self.keywords[self.category])\n",
    "\n",
    "        # Simulate the answer\n",
    "        answer = self._simulate_answer(question)\n",
    "\n",
    "        # Calculate reward\n",
    "        reward = self._calculate_reward(question, answer)\n",
    "\n",
    "        # Track asked questions\n",
    "        self.asked_questions.append((question, answer))\n",
    "\n",
    "        # Check termination condition\n",
    "        self.steps += 1\n",
    "        if self.steps >= self.max_steps or answer == \"Yes, correct!\":\n",
    "            self.done = True\n",
    "\n",
    "        return np.array(self._get_state()), reward, self.done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Resets the environment for a new game\"\"\"\n",
    "        self.category = random.choice(list(self.keywords.keys()))\n",
    "        self.secret_word = random.choice(self.keywords[self.category])\n",
    "        self.asked_questions = []\n",
    "        self.done = False\n",
    "        self.steps = 0\n",
    "        return np.array(self._get_state())\n",
    "\n",
    "    def _get_state(self):\n",
    "        \"\"\"Returns the current game state\"\"\"\n",
    "        return [len(self.asked_questions)]  # Simplified representation\n",
    "\n",
    "    def _simulate_answer(self, question):\n",
    "        \"\"\"Simulates Yes/No/Maybe answers\"\"\"\n",
    "        if any(keyword in question.lower() for keyword in self.keywords[self.category]):\n",
    "            return random.choices([\"Yes\", \"Maybe\"], weights=[0.8, 0.2], k=1)[0]\n",
    "        return random.choices([\"No\", \"Maybe\"], weights=[0.7, 0.3], k=1)[0]\n",
    "\n",
    "    def _calculate_reward(self, question, answer):\n",
    "        \"\"\"Rewards/Penalizes the agent based on question quality\"\"\"\n",
    "        if answer == \"Yes\":\n",
    "            return 1  # Good question\n",
    "        elif answer == \"Maybe\":\n",
    "            return -0.5  # Weak question\n",
    "        elif answer == \"No\":\n",
    "            return -2  # Bad question\n",
    "        return -1  # Default penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28101eeb-2ca8-412d-821e-a73bea2588ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class PPOAgent:\n",
    "    def __init__(self, state_size, action_size, lr=0.001):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.lr = lr\n",
    "\n",
    "        # Create models\n",
    "        self.policy_model = self._build_policy_model()\n",
    "        self.value_model = self._build_value_model()\n",
    "\n",
    "        # 🔹 Ensure models are built before use\n",
    "        self.policy_model.build((None, self.state_size))\n",
    "        self.value_model.build((None, self.state_size))\n",
    "\n",
    "        # Optimizers\n",
    "        self.policy_optimizer = tf.keras.optimizers.Adam(learning_rate=self.lr)\n",
    "        self.value_optimizer = tf.keras.optimizers.Adam(learning_rate=self.lr)\n",
    "\n",
    "    def _build_policy_model(self):\n",
    "        \"\"\"Defines the policy network (actor).\"\"\"\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='relu', input_shape=(self.state_size,)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(self.action_size, activation='softmax')\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "    def _build_value_model(self):\n",
    "        \"\"\"Defines the value network (critic).\"\"\"\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='relu', input_shape=(self.state_size,)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='linear')\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "    def get_action(self, state):\n",
    "        \"\"\"Selects an action (question)\"\"\"\n",
    "        state = np.array([state], dtype=np.float32)  # 🔹 Ensure correct shape\n",
    "        probs = self.policy_model.predict(state, verbose=0)[0]\n",
    "        return np.random.choice(self.action_size, p=probs)\n",
    "\n",
    "    def train(self, states, actions, rewards):\n",
    "        \"\"\"Trains PPO Agent\"\"\"\n",
    "        states = np.array(states, dtype=np.float32)\n",
    "        actions = np.array(actions, dtype=np.int32)\n",
    "        rewards = np.array(rewards, dtype=np.float32)\n",
    "\n",
    "        # Compute advantages\n",
    "        advantages = rewards - self.value_model.predict(states, verbose=0).flatten()\n",
    "\n",
    "        with tf.GradientTape() as policy_tape, tf.GradientTape() as value_tape:\n",
    "            probs = self.policy_model(states)\n",
    "            action_masks = tf.one_hot(actions, self.action_size)\n",
    "            selected_probs = tf.reduce_sum(probs * action_masks, axis=1)\n",
    "\n",
    "            # PPO Loss\n",
    "            loss = -tf.reduce_mean(tf.math.log(selected_probs + 1e-10) * advantages)\n",
    "\n",
    "            # Value Loss\n",
    "            value_preds = self.value_model(states)\n",
    "            value_loss = tf.reduce_mean(tf.square(rewards - value_preds))\n",
    "\n",
    "        policy_grads = policy_tape.gradient(loss, self.policy_model.trainable_variables)\n",
    "        value_grads = value_tape.gradient(value_loss, self.value_model.trainable_variables)\n",
    "\n",
    "        self.policy_optimizer.apply_gradients(zip(policy_grads, self.policy_model.trainable_variables))\n",
    "        self.value_optimizer.apply_gradients(zip(value_grads, self.value_model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8f312f9-51f5-431a-b1fb-10eab890d3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-03-05 07:14:20.820204: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward: -34.0\n",
      "Episode 2: Total Reward: -31.0\n",
      "Episode 3: Total Reward: 11.0\n",
      "Episode 4: Total Reward: -31.0\n",
      "Episode 5: Total Reward: -29.5\n",
      "Episode 6: Total Reward: -32.5\n",
      "Episode 7: Total Reward: -28.0\n",
      "Episode 8: Total Reward: -29.5\n",
      "Episode 9: Total Reward: 18.5\n",
      "Episode 10: Total Reward: -28.0\n"
     ]
    }
   ],
   "source": [
    "env = TwentyQuestionsEnv(keywords)\n",
    "agent = PPOAgent(state_size=1, action_size=20)\n",
    "\n",
    "#tf.keras.backend.clear_session()  # Clears the previous model state\n",
    "\n",
    "for episode in range(10):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    states, actions, rewards = [], [], []\n",
    "\n",
    "    for t in range(env.max_steps):\n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    agent.train(states, actions, rewards)\n",
    "    print(f\"Episode {episode+1}: Total Reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ecff8-8f1c-459f-9209-bee6b1137951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92c24c0-522c-400b-ba39-416ea152ce39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
